{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4140f378-cdd3-4e94-bfb1-e747f547a929",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Variant folder C:\\Users\\greys\\tensorflow_datasets\\emnist\\digits\\3.1.0 has no dataset_info.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\greys\\tensorflow_datasets\\emnist\\digits\\3.1.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "991a2f944846469cbc8b4cb50df1ee5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "577b0d389c09472080e3dfd49c5b279a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4927e3a1f9c24c39a043bb43c17cce8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eacfd8c260434b69a99eb1363472a052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling C:\\Users\\greys\\tensorflow_datasets\\emnist\\digits\\incomplete.4DO4LN_3.1.0\\emnist-train.tfrecord*...: …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling C:\\Users\\greys\\tensorflow_datasets\\emnist\\digits\\incomplete.4DO4LN_3.1.0\\emnist-test.tfrecord*...:  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset emnist downloaded and prepared to C:\\Users\\greys\\tensorflow_datasets\\emnist\\digits\\3.1.0. Subsequent calls will reuse this data.\u001b[0m\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds # Do \"pip install tensorflow_datasets\" in an Anaconda prompt, or however you manage your packages.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load MNIST (via EMNIST?)\n",
    "\n",
    "\n",
    "# Load EMNIST. Use a split with balanced classes.\n",
    "(train_ds, test_ds), ds_info = tfds.load(\n",
    "    'emnist/digits',  #  Could also try emnist/letters or emnist/balanced \n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,  # Shuffle training data\n",
    "    as_supervised=True,  # Return (image, label) tuples\n",
    "    with_info=True      # Include dataset metadata\n",
    ")\n",
    "\n",
    "def preprocess(image, label):\n",
    "    # Rotate images 90 degrees counterclockwise (they're 90 degrees clockwise from the upright orientation)\n",
    "    image = tf.transpose(image, [1, 0, 2])\n",
    "    # Normalize pixels to 0..1\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    # Adjust labels for 0-indexing\n",
    "    label = label - 1\n",
    "    return image, label\n",
    "\n",
    "## Apply preprocessing to both datasets.\n",
    "train_ds = train_ds.map(preprocess).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.map(preprocess).batch(32)\n",
    "\n",
    "# Load Fashion MNIST. (Probably should do this through tfds instead of tf for consistency?\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "## Images are unnormalized 28x28 NumPy arrays. Labels already 0-indexed.\n",
    "## https://www.tensorflow.org/tutorials/keras/classification\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d69008-62bb-4d3a-93e5-765595071a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train KNN models on each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6e4bd6-9c67-4666-b7fe-c896ac3ec8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Random Forest models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626297fb-7afb-4086-ac2c-7986a9b6333a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
